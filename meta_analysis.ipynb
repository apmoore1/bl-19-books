{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta data analysis of the 19th Century Books from the British Library\n",
    "\n",
    "This notebook will review the meta data that comes with the [19th Century book corpus from the British Library.](https://data.bl.uk/digbks/db14.html)\n",
    "\n",
    "## Load the data\n",
    "\n",
    "Below we show how to load the data into a python `List` whereby each book's meta data is stored as an item in the lists' collection: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "--------- META DATA START -------\n{\n    \"authors\": {},\n    \"corporate\": {},\n    \"date\": \"1888\",\n    \"datefield\": \"[1888]\",\n    \"edition\": \"\",\n    \"flickr_url_to_book_images\": \"http://www.flickr.com/photos/britishlibrary/tags/sysnum000000037\",\n    \"identifier\": \"000000037\",\n    \"imgs\": {\n        \"0\": {\n            \"000004\": [\n                \"11194557546\"\n            ],\n            \"000006\": [\n                \"11193640604\"\n            ],\n            \"000007\": [\n                \"11104733396\"\n            ],\n            \"000010\": [\n                \"11105407186\",\n                \"11102797916\"\n            ],\n            \"000011\": [\n                \"11193211526\"\n            ],\n            \"000012\": [\n                \"11290477144\"\n            ],\n            \"000014\": [\n                \"11291300706\"\n            ],\n            \"000015\": [\n                \"11100321335\"\n            ],\n            \"000016\": [\n                \"11195895503\"\n            ],\n            \"000021\": [\n                \"11291327843\"\n            ],\n            \"000023\": [\n                \"11289589926\"\n            ],\n            \"000024\": [\n                \"11291438044\"\n            ],\n            \"000025\": [\n                \"11289879506\"\n            ],\n            \"000027\": [\n                \"11196186866\"\n            ],\n            \"000030\": [\n                \"11289521295\"\n            ],\n            \"000031\": [\n                \"11289757376\"\n            ],\n            \"000032\": [\n                \"11105696613\"\n            ],\n            \"000033\": [\n                \"11193563513\"\n            ],\n            \"000035\": [\n                \"11290567494\"\n            ],\n            \"000037\": [\n                \"11290757205\"\n            ]\n        }\n    },\n    \"issuance\": \"monographic\",\n    \"pdf\": {\n        \"0\": \"lsidyv3bd2589c\"\n    },\n    \"place\": \"Manchester\",\n    \"publisher\": \"A. Heywood & Son\",\n    \"shelfmarks\": [\n        \"British Library HMNTS 10347.cc.13.(4.)\"\n    ],\n    \"title\": [\n        \"A Gossip about Old Manchester. With illustrations. [Signed: A.]\"\n    ]\n}\n--------- META DATA END -------\nThe number of books 49509\nAre all books unique based on their identifier field? True\n"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Set\n",
    "\n",
    "def load_book_meta_data(book_data_fp: Path=Path('.', 'book_data.json').resolve()\n",
    "                        ) -> List[Dict[str, Any]]:\n",
    "    with book_data_fp.open('r') as book_data_file:\n",
    "        return json.load(book_data_file)\n",
    "\n",
    "def unique_identifiers(book_data: List[Dict[str, Any]]) -> Set[str]:\n",
    "    '''\n",
    "    :returns: A set of unique book identifiers.\n",
    "    '''\n",
    "    identifiers = set()\n",
    "    for book in book_data:\n",
    "        identifiers.add(book['identifier'])\n",
    "    return identifiers\n",
    "\n",
    "\n",
    "book_meta_data = load_book_meta_data()\n",
    "print('--------- META DATA START -------')\n",
    "print(json.dumps(book_meta_data[0], indent=4, sort_keys=True))\n",
    "print('--------- META DATA END -------')\n",
    "print(f'The number of books {len(book_meta_data)}')\n",
    "print('Are all books unique based on their identifier field? '\n",
    "      f'{len(unique_identifiers(book_meta_data))==len(book_meta_data)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see that we have loaded all of the books meta data into the `book_meta_data` list, and the first item in that lists' collection represents the meta data for the book `A Gossip about Old Manchester. With illustrations. [Signed: A.]`\n",
    "\n",
    "Also as the meta data has been loaded as a list we can see, easily, that there are **49,509** books. However according to the [British Library OCR book corpus that contains the full text](https://data.bl.uk/digbks/db14.html) there should only be **49,455** books, thus above we also check that all of the books meta data unique identifier are unique of which we find that they are. Thus the difference in full OCR text book count could be due to the British Library releasing a smaller book corpus of OCR text books compared to the releated meta data that we are analysing here. \n",
    "\n",
    "However we show below that there are 4 books, list indexs `[9122, 14699, 33207, 46786]`, that contain no pdfs of which an example is shown as output below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Indexes of books that contain no PDFs [9122, 14699, 33207, 46786]\nExample of index 9122:\n{\n    \"authors\": {\n        \"creator\": [\n            \"COLEMAN, F. M.\"\n        ]\n    },\n    \"corporate\": {},\n    \"date\": \"1807\",\n    \"datefield\": \"1807\",\n    \"edition\": \"\",\n    \"flickr_url_to_book_images\": \"http://www.flickr.com/photos/britishlibrary/tags/sysnum000741339\",\n    \"identifier\": \"000741339\",\n    \"imgs\": {\n        \"0\": {\n            \"000007\": [\n                \"11001418734\"\n            ],\n            \"000008\": [\n                \"11000688195\"\n            ],\n            \"000010\": [\n                \"11001417834\"\n            ],\n            \"000012\": [\n                \"11001292025\",\n                \"11001377336\",\n                \"11219716895\"\n            ],\n            \"000013\": [\n                \"11001516523\"\n            ],\n            \"000014\": [\n                \"11219712374\"\n            ],\n            \"000016\": [\n                \"11219715495\"\n            ],\n            \"000018\": [\n                \"11001148703\"\n            ],\n            \"000022\": [\n                \"11000915306\"\n            ],\n            \"000027\": [\n                \"11000915765\"\n            ],\n            \"000031\": [\n                \"11000833886\"\n            ],\n            \"000035\": [\n                \"11000676935\"\n            ],\n            \"000039\": [\n                \"11001014233\"\n            ],\n            \"000043\": [\n                \"11001057394\"\n            ],\n            \"000047\": [\n                \"11000816065\"\n            ],\n            \"000051\": [\n                \"11000934415\"\n            ],\n            \"000053\": [\n                \"11000929054\"\n            ],\n            \"000055\": [\n                \"11000983144\"\n            ],\n            \"000059\": [\n                \"11000949503\"\n            ],\n            \"000063\": [\n                \"11000886536\"\n            ],\n            \"000067\": [\n                \"11000820884\"\n            ],\n            \"000071\": [\n                \"11000834745\"\n            ],\n            \"000075\": [\n                \"11001140313\"\n            ],\n            \"000079\": [\n                \"11000864954\"\n            ],\n            \"000083\": [\n                \"11001017755\"\n            ],\n            \"000087\": [\n                \"11000983615\"\n            ],\n            \"000091\": [\n                \"11000896406\"\n            ],\n            \"000095\": [\n                \"11000789065\"\n            ],\n            \"000099\": [\n                \"11000891803\"\n            ],\n            \"000103\": [\n                \"11000785326\"\n            ],\n            \"000107\": [\n                \"11001018004\"\n            ],\n            \"000111\": [\n                \"11000695075\"\n            ],\n            \"000115\": [\n                \"11001289265\"\n            ],\n            \"000119\": [\n                \"11001453614\",\n                \"11219837423\"\n            ]\n        }\n    },\n    \"issuance\": \"monographic\",\n    \"place\": \"Bombay\",\n    \"publisher\": \"\\u201cTimes of India\\u201d Office\",\n    \"shelfmarks\": [\n        \"British Library HMNTS 10056.f.30.\"\n    ],\n    \"title\": [\n        \"Typical Pictures of Indian Natives: being reproductions from specially-prepared hand-coloured photographs. With descriptive letterpress by F. M. Coleman\"\n    ]\n}\n"
    }
   ],
   "source": [
    "def books_with_no_pdfs(book_data: List[Dict[str, Any]]) -> List[int]:\n",
    "    '''\n",
    "    :return: A list of indexes whereby each index refers to an index in \n",
    "             the given `book_data` list whereby the meta data contains \n",
    "             no pdf data.\n",
    "    '''\n",
    "    no_pdf_indexes = []\n",
    "    for index, book in enumerate(book_data):\n",
    "        if 'pdf' not in book:\n",
    "            no_pdf_indexes.append(index)\n",
    "    return no_pdf_indexes\n",
    "print(f'Indexes of books that contain no PDFs {books_with_no_pdfs(book_meta_data)}')\n",
    "print(f'Example of index 9122:\\n{json.dumps(book_meta_data[9122], indent=4, sort_keys=True)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the 4 above books contain no PDFs they all contain images and other meta data thus we keep these samples in all further analysis. This has only been highlighted to show that some books do not contain PDFs.\n",
    "\n",
    "### Date formatting\n",
    "\n",
    "Within the [meta data](https://data.bl.uk/digbks/DB21.html) description they state that the `date` key/field is a more standard version of the `datefield` key, here we show some differences between the two by displaying the first 5 differences between the `date` and `datefield`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "date: 1879    datefield: 1879 [1878\ndate: 1898    datefield: \ndate: 1887    datefield: 1887.\ndate: 1886    datefield: 1886.\ndate: 1840    datefield: 1840-51\n"
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "def difference_in_datefield(book_data: List[Dict[str, Any]]) -> List[Tuple[str, str]]:\n",
    "    '''\n",
    "    :returns: A list of tuples containing the `date` and the `datefield`\n",
    "              values respectively for books where these values differ.\n",
    "    '''\n",
    "    date_differences = []\n",
    "    for book in book_data:\n",
    "        datefield = book['datefield'].strip('[]')\n",
    "        date = book['date'].strip('[]')\n",
    "        if datefield != date:\n",
    "            date_differences.append((date, datefield))\n",
    "    return date_differences\n",
    "date_differences = difference_in_datefield(book_meta_data)\n",
    "for date, datefield in date_differences[:5]:\n",
    "    print(f'date: {date}    datefield: {datefield}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the `date` key is a lot more standardised and should be used when wanting the date of a book.\n",
    "\n",
    "### Explore all possible meta data keys\n",
    "\n",
    "Here we look at all the possible meta data and how often it occurs as a percentage of the whole corpus:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{\n    \"authors\": \"86.24\",\n    \"corporate\": \"3.57\",\n    \"date\": \"99.72\",\n    \"datefield\": \"96.91\",\n    \"edition\": \"8.33\",\n    \"flickr_url_to_book_images\": \"100.00\",\n    \"identifier\": \"100.00\",\n    \"imgs\": \"62.98\",\n    \"issuance\": \"100.00\",\n    \"pdf\": \"99.99\",\n    \"place\": \"99.07\",\n    \"publisher\": \"48.83\",\n    \"shelfmarks\": \"100.00\",\n    \"title\": \"100.00\"\n}\n"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "book_meta_data_keys = Counter()\n",
    "number_books = len(book_meta_data)\n",
    "for book in book_meta_data:\n",
    "    for key, value in book.items():\n",
    "        if key == 'authors':\n",
    "            if 'creator' in value:\n",
    "                book_meta_data_keys.update([key])\n",
    "        elif key == 'place':\n",
    "            if value:\n",
    "                if value.strip():\n",
    "                    book_meta_data_keys.update([key])\n",
    "        elif value:\n",
    "            book_meta_data_keys.update([key])\n",
    "book_meta_data_keys = {key: f'{round(float(value) / number_books, 4) * 100:.2f}'\n",
    "                       for key, value in book_meta_data_keys.items()}\n",
    "print(json.dumps(book_meta_data_keys, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above not all of the meta data exists for all books.\n",
    "\n",
    "## Metadata\n",
    "\n",
    "The following is probably the metadata we would want to collect, based on the statistics we created in the [explore all possible meta data keys section](#explore-all-possible-meta-data-keys):\n",
    "\n",
    "1. Identifier -- 100%\n",
    "2. Date -- 99.72%\n",
    "3. Publisher -- 48.83%\n",
    "4. Title -- 100%\n",
    "5. Place -- 99.07%\n",
    "6. Authors -- 86.24% -- The authors meta data actually contains the following information `['Former owner', 'contributor', 'creator', 'engraver', 'fmo', 'former owner']`, we are assuming that the `creator` is the author of the book.\n",
    "\n",
    "The meta data that is missing the most from this list is the `publisher` whereby only `48.83%` of the books have this meta data.\n",
    "\n",
    "### Number of volumes\n",
    "\n",
    "The other piece of meta data that might be useful to sotre is the `volume` number of the book. This volume number can be found through the `pdf` and `imgs` meta data field. Below we show a table containing the prcentage of books that have the given number of volumes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "volumes        1        2        3       4       5       6      7     8   \\\ncount    42448.00  3108.00  3106.00  287.00  155.00  113.00  52.00  51.0   \n%           85.74     6.28     6.27    0.58    0.31    0.23   0.11   0.1   \n\nvolumes     9     10     11     12     13    14    15    16    17    18    19  \\\ncount    27.00  48.0  18.00  22.00  10.00  9.00  6.00  4.00  6.00  6.00  6.00   \n%         0.05   0.1   0.04   0.04   0.02  0.02  0.01  0.01  0.01  0.01  0.01   \n\nvolumes    20   21    22   23    24    25   26   28   29   34   39   41   65  \ncount    3.00  1.0  3.00  1.0  6.00  3.00  1.0  2.0  1.0  2.0  1.0  2.0  1.0  \n%        0.01  0.0  0.01  0.0  0.01  0.01  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>volumes</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>28</th>\n      <th>29</th>\n      <th>34</th>\n      <th>39</th>\n      <th>41</th>\n      <th>65</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42448.00</td>\n      <td>3108.00</td>\n      <td>3106.00</td>\n      <td>287.00</td>\n      <td>155.00</td>\n      <td>113.00</td>\n      <td>52.00</td>\n      <td>51.0</td>\n      <td>27.00</td>\n      <td>48.0</td>\n      <td>18.00</td>\n      <td>22.00</td>\n      <td>10.00</td>\n      <td>9.00</td>\n      <td>6.00</td>\n      <td>4.00</td>\n      <td>6.00</td>\n      <td>6.00</td>\n      <td>6.00</td>\n      <td>3.00</td>\n      <td>1.0</td>\n      <td>3.00</td>\n      <td>1.0</td>\n      <td>6.00</td>\n      <td>3.00</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>%</th>\n      <td>85.74</td>\n      <td>6.28</td>\n      <td>6.27</td>\n      <td>0.58</td>\n      <td>0.31</td>\n      <td>0.23</td>\n      <td>0.11</td>\n      <td>0.1</td>\n      <td>0.05</td>\n      <td>0.1</td>\n      <td>0.04</td>\n      <td>0.04</td>\n      <td>0.02</td>\n      <td>0.02</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def number_volumes_per_book(book_data: List[Dict[str, Any]]) -> Dict[str, List[int]]:\n",
    "    '''\n",
    "    :returns: A dictionary with two keys: volumes and count. Where the\n",
    "              volumes key contains a list of integers representing the \n",
    "              volumes that exist for all books. The count contains a \n",
    "              same size list with the counts for the corresponding \n",
    "              volumes.\n",
    "    '''\n",
    "    volumes_counter = Counter()\n",
    "    for book in book_data:\n",
    "        volume = None\n",
    "        if 'pdf' not in book:\n",
    "            volume = len(book['imgs'])\n",
    "        else:\n",
    "            volume = len(book['pdf'])\n",
    "        volumes_counter.update([volume])\n",
    "    volumes_count = {'volumes': [], 'count': []}\n",
    "    for volume, count in volumes_counter.items():\n",
    "        volumes_count['volumes'].append(volume)\n",
    "        volumes_count['count'].append(count)\n",
    "    return volumes_count\n",
    "\n",
    "number_books = len(book_meta_data)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    volume_count = number_volumes_per_book(book_meta_data)\n",
    "    volume_count['%'] = [(count / number_books) * 100 for count in volume_count['count']]\n",
    "    df = pd.DataFrame(volume_count)\n",
    "    display(df.set_index('volumes').sort_index().T.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the majority of book (85.74%) of books only have one volume and ~98.3% of books have at most 3 volumes. Thus not many of the books in the collection have more than one volume and very few have more than 3 volumes.\n",
    "\n",
    "### Date overview\n",
    "\n",
    "Here we show the number of book in this dataset per decade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "decade        1510  1520  1540  1550  1560  1570  1580  1590   1600   1610  \\\ncount          1.0   1.0  1.00  1.00  1.00  2.00  1.00  5.00  12.00  13.00   \nCumulative %   0.0   0.0  0.01  0.01  0.01  0.01  0.02  0.03   0.05   0.08   \n\ndecade        1620    1630  1640   1650   1660    1670    1680    1690   1700  \\\ncount         12.0  103.00  47.0  41.00  74.00  119.00  108.00  146.00  91.00   \nCumulative %   0.1    0.31   0.4   0.49   0.64    0.88    1.09    1.39   1.57   \n\ndecade         1710   1720    1730   1740    1750   1760    1770    1780  \\\ncount         88.00  68.00  143.00  95.00  136.00  177.0  282.00  315.00   \nCumulative %   1.75   1.89    2.18   2.37    2.64    3.0    3.57    4.21   \n\ndecade          1790     1800     1810     1820     1830     1840     1850  \\\ncount         417.00  1139.00  1937.00  1963.00  2086.00  3228.00  4678.00   \nCumulative %    5.05     7.35    11.26    15.23    19.44    25.96    35.41   \n\ndecade           1860     1870     1880      1890   1900   1910   1920   1930  \\\ncount         5258.00  6156.00  8102.00  12072.00  98.00  68.00  78.00   1.00   \nCumulative %    46.03    58.46    74.83     99.21  99.41  99.55  99.71  99.71   \n\ndecade         1940  \ncount          5.00  \nCumulative %  99.72  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>decade</th>\n      <th>1510</th>\n      <th>1520</th>\n      <th>1540</th>\n      <th>1550</th>\n      <th>1560</th>\n      <th>1570</th>\n      <th>1580</th>\n      <th>1590</th>\n      <th>1600</th>\n      <th>1610</th>\n      <th>1620</th>\n      <th>1630</th>\n      <th>1640</th>\n      <th>1650</th>\n      <th>1660</th>\n      <th>1670</th>\n      <th>1680</th>\n      <th>1690</th>\n      <th>1700</th>\n      <th>1710</th>\n      <th>1720</th>\n      <th>1730</th>\n      <th>1740</th>\n      <th>1750</th>\n      <th>1760</th>\n      <th>1770</th>\n      <th>1780</th>\n      <th>1790</th>\n      <th>1800</th>\n      <th>1810</th>\n      <th>1820</th>\n      <th>1830</th>\n      <th>1840</th>\n      <th>1850</th>\n      <th>1860</th>\n      <th>1870</th>\n      <th>1880</th>\n      <th>1890</th>\n      <th>1900</th>\n      <th>1910</th>\n      <th>1920</th>\n      <th>1930</th>\n      <th>1940</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>5.00</td>\n      <td>12.00</td>\n      <td>13.00</td>\n      <td>12.0</td>\n      <td>103.00</td>\n      <td>47.0</td>\n      <td>41.00</td>\n      <td>74.00</td>\n      <td>119.00</td>\n      <td>108.00</td>\n      <td>146.00</td>\n      <td>91.00</td>\n      <td>88.00</td>\n      <td>68.00</td>\n      <td>143.00</td>\n      <td>95.00</td>\n      <td>136.00</td>\n      <td>177.0</td>\n      <td>282.00</td>\n      <td>315.00</td>\n      <td>417.00</td>\n      <td>1139.00</td>\n      <td>1937.00</td>\n      <td>1963.00</td>\n      <td>2086.00</td>\n      <td>3228.00</td>\n      <td>4678.00</td>\n      <td>5258.00</td>\n      <td>6156.00</td>\n      <td>8102.00</td>\n      <td>12072.00</td>\n      <td>98.00</td>\n      <td>68.00</td>\n      <td>78.00</td>\n      <td>1.00</td>\n      <td>5.00</td>\n    </tr>\n    <tr>\n      <th>Cumulative %</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>0.03</td>\n      <td>0.05</td>\n      <td>0.08</td>\n      <td>0.1</td>\n      <td>0.31</td>\n      <td>0.4</td>\n      <td>0.49</td>\n      <td>0.64</td>\n      <td>0.88</td>\n      <td>1.09</td>\n      <td>1.39</td>\n      <td>1.57</td>\n      <td>1.75</td>\n      <td>1.89</td>\n      <td>2.18</td>\n      <td>2.37</td>\n      <td>2.64</td>\n      <td>3.0</td>\n      <td>3.57</td>\n      <td>4.21</td>\n      <td>5.05</td>\n      <td>7.35</td>\n      <td>11.26</td>\n      <td>15.23</td>\n      <td>19.44</td>\n      <td>25.96</td>\n      <td>35.41</td>\n      <td>46.03</td>\n      <td>58.46</td>\n      <td>74.83</td>\n      <td>99.21</td>\n      <td>99.41</td>\n      <td>99.55</td>\n      <td>99.71</td>\n      <td>99.71</td>\n      <td>99.72</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "book_decades_count = Counter()\n",
    "for book in book_meta_data:\n",
    "    if 'date' in book:\n",
    "        if book['date']:\n",
    "            book_decades_count.update([(int(book['date']) // 10) * 10])\n",
    "book_decade = []\n",
    "decade_count = []\n",
    "decade_cuml_freq = []\n",
    "current_cuml_freq = 0\n",
    "for decade, count in sorted(book_decades_count.items(), key=lambda x: x[0]):\n",
    "    book_decade.append(decade)\n",
    "    decade_count.append(count)\n",
    "    count_percentage = ((float(count) / number_books) * 100) + current_cuml_freq\n",
    "    decade_cuml_freq.append(count_percentage)\n",
    "    current_cuml_freq = count_percentage\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    df = pd.DataFrame({'decade': book_decade, 'count': decade_count, 'Cumulative %': decade_cuml_freq})\n",
    "    display((df.set_index('decade').sort_index().T).round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "As we can see very few books exist in this dataset until the 19th century (this can be best seen through the `Cumulative %` row), furthermore in comparison to the 19th century the 20th centruy decades contain very few book within this dataset. \n",
    "\n",
    "### Author overview\n",
    "\n",
    "Here we show the number of authors and how frequent each author is in our dataset, all author names are normalised by lower casing them and removing any whitespace either side of the name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Top 20 authors\nAuthor: byron, george gordon byron - baron\nBooks written within this dataset: 154\nAuthor: scott, walter - sir\nBooks written within this dataset: 106\nAuthor: wood, henry - mrs\nBooks written within this dataset: 103\nAuthor: dickens, charles\nBooks written within this dataset: 79\nAuthor: oliphant, (margaret) - mrs\nBooks written within this dataset: 74\nAuthor: shakespeare, william\nBooks written within this dataset: 62\nAuthor: marryat, afterwards church, afterwards lean, florence.\nBooks written within this dataset: 58\nAuthor: goldsmith, oliver\nBooks written within this dataset: 55\nAuthor: ainsworth, william harrison\nBooks written within this dataset: 47\nAuthor: dryden, john.\nBooks written within this dataset: 47\nAuthor: burns, robert\nBooks written within this dataset: 46\nAuthor: payn, james\nBooks written within this dataset: 42\nAuthor: fenn, george manville.\nBooks written within this dataset: 41\nAuthor: norie, john william.\nBooks written within this dataset: 41\nAuthor: carey, rosa nouchette.\nBooks written within this dataset: 40\nAuthor: marshall, emma\nBooks written within this dataset: 40\nAuthor: riddell, j. h. - mrs\nBooks written within this dataset: 40\nAuthor: besant, walter - sir\nBooks written within this dataset: 39\nAuthor: pindar, peter - pseud. [i.e. john wolcot.]\nBooks written within this dataset: 39\nAuthor: thomas, afterwards cudlip, annie hall.\nBooks written within this dataset: 39\n\nTotal number of authors in the dataset: 25558\nNumber of authors that only have one book in the dataset: 19249\n"
    }
   ],
   "source": [
    "author_counter = Counter()\n",
    "\n",
    "for book in book_meta_data:\n",
    "    if 'authors' in book:\n",
    "        if book['authors']:\n",
    "            if 'creator' in book['authors']:\n",
    "                creator = book['authors']['creator']\n",
    "                assert len(creator) == 1\n",
    "                creator = creator[0].strip().lower()\n",
    "                author_counter.update([creator])\n",
    "# Top 20 authors:\n",
    "print('Top 20 authors')\n",
    "for author, count in author_counter.most_common(20):\n",
    "    print(f'Author: {author}\\nBooks written within this dataset: {count}')\n",
    "# Total number of authors\n",
    "print()\n",
    "print(f'Total number of authors in the dataset: {len(author_counter)}')\n",
    "single_authors = sum([count for count in author_counter.values() if count == 1])\n",
    "print(f'Number of authors that only have one book in the dataset: {single_authors}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there are a lot of authors that only published once in the dataset (19,249). On the other hand from the top 20 published authors in this dataset the most published has 154 book in the dataset (George Gordon Byron). From the author names we can also see that the names are full names containing the authors titles e.g. Baron, Sir, etc.\n",
    "\n",
    "### Place overview\n",
    "\n",
    "Here we are going to explore the `place` meta data in the same way as we did with authors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Top 20 places\nPlace: london\tCount: 23405\nPlace: paris\tCount: 2165\nPlace: new york\tCount: 1093\nPlace: edinburgh\tCount: 1033\nPlace: leipzig\tCount: 514\nPlace: philadelphia\tCount: 442\nPlace: berlin\tCount: 425\nPlace: dublin\tCount: 381\nPlace: boston [mass.]\tCount: 247\nPlace: wien\tCount: 240\nPlace: boston\tCount: 238\nPlace: glasgow\tCount: 214\nPlace: bruxelles\tCount: 206\nPlace: chicago\tCount: 187\nPlace: oxford\tCount: 181\nPlace: calcutta\tCount: 175\nPlace: manchester\tCount: 166\nPlace: stockholm\tCount: 166\nPlace: madrid\tCount: 153\nPlace: kjøbenhavn\tCount: 143\n\nTotal number of places in the dataset: 5370\nNumber of places that only have one book in the dataset: 3764\n"
    }
   ],
   "source": [
    "place_counter = Counter()\n",
    "\n",
    "for book in book_meta_data:\n",
    "    if 'place' in book:\n",
    "        place = book['place'].strip().lower()\n",
    "        if place:\n",
    "            place_counter.update([place])\n",
    "\n",
    "print('Top 20 places')\n",
    "for place, count in place_counter.most_common(20):\n",
    "    print(f'Place: {place}\\tCount: {count}')\n",
    "\n",
    "print()\n",
    "print(f'Total number of places in the dataset: {len(place_counter)}')\n",
    "single_places = sum([count for count in place_counter.values() if count == 1])\n",
    "print(f'Number of places that only have one book in the dataset: {single_places}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparison to the authors there are far fewer places (5371), further London takes up more than `50%` of the dataset. However there are still `3764` places that only have one book attached to them. The names might be difficult to automatically match to their actually place name e.g. \"Boston \\[mass.\\]\" should be \"Boston Massachusetts\". To look into this we shall use the [geonames](http://download.geonames.org/export/dump/) `allCountries.zip` list of country and city names to see how many of the place names we can link with an actually location: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of country and city names in the geonames list: 15106416\n"
    }
   ],
   "source": [
    "country_name_fp = Path('.', 'CountriesNamesAlt.txt').resolve()\n",
    "all_city_and_country_names = set()\n",
    "with country_name_fp.open('r') as country_name_file:\n",
    "    for name in country_name_file:\n",
    "        name = name.strip()\n",
    "        if name:\n",
    "            all_city_and_country_names.add(name.lower())\n",
    "print(f'Number of country and city names in the geonames list: {len(all_city_and_country_names)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of unique places that we cannot identify: 3566\nNumber of books whose place name cannot be resolved to a name in geonames: 7154\n"
    }
   ],
   "source": [
    "places_cannot_identify = []\n",
    "place_split_lengths = Counter()\n",
    "for place in place_counter.keys():\n",
    "    if place not in all_city_and_country_names:\n",
    "        place_split_length = len(place.split(','))\n",
    "        place_split_lengths.update([place_split_length])\n",
    "        places_cannot_identify.append(place)\n",
    "print(f'Number of unique places that we cannot identify: {len(places_cannot_identify)}')\n",
    "books_with_places_cannot_identify = 0\n",
    "for place in places_cannot_identify:\n",
    "    books_with_places_cannot_identify += place_counter[place]\n",
    "print(f'Number of books whose place name cannot be resolved to a name in geonames: {books_with_places_cannot_identify}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading and lower caseing the geonames place names, we have 15 million place names from geonames to compare the book place names too. Out of the 5370 unique place names we can match 1804 and not resolve 3566 place names. 3566 place names does seem like a lot of place name however from the whole book collection (49,509) those 3566 unique place names only affect 7154 books. Out of the 7154 book below shows the top 20 unique place names that affects the most books:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('boston [mass.]', 247),\n ('kjøbenhavn', 143),\n ('с.-петербургъ', 129),\n ('edinburgh & london', 120),\n ('new-york', 97),\n ('münchen', 85),\n ('london, guildford [printed]', 80),\n ('санктпетербургъ', 78),\n ('edinburgh and london', 74),\n ('london]', 72),\n ('london & new york', 64),\n ('méxico', 59),\n ('london; guildford [printed]', 56),\n (\"'s gravenhage\", 51),\n ('london; edinburgh [printed]', 51),\n ('london, edinburgh [printed]', 51),\n ('zürich', 50),\n ('genève', 40),\n ('v praze', 35),\n ('с. петербургъ', 32)]"
     },
     "metadata": {},
     "execution_count": 192
    }
   ],
   "source": [
    "place_counter_no_name = Counter()\n",
    "for place in places_cannot_identify:\n",
    "    place_counter_no_name[place] = place_counter[place]\n",
    "place_counter_no_name.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see `boston [mass.]` and `kjøbenhavn` affects the most books and if resolved will affect in total 390 books. There are a fair few place names that contain more than one place name e.g. `edinburgh & london`, some have extra text that needs to be removed e.g. `[printed]`, some are in the native language e.g. `с. петербургъ` which I believe is `Saint Petersburg`. Below shows the unique place names that cannot be resolved but affect the least number of books, of which these show larger errors which can mainly fall into the topic of extra text that is not relevant to the place name e.g. including the date.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('london: w. oxberry; sold by sherwood, neely & jones, 1812', 1),\n ('london: lowndes & hobbs; sold by hatchard, [1811]', 1),\n ('london: d. wilson & t. durham, 1752', 1),\n ('london: t. n. longman & o. rees, 1800', 1),\n ('london: richard bentley & son, 1885', 1),\n ('london: printed for nicholas vavasour, 1634', 1),\n ('london: macmillan & co., pp. xl, 400. 1895', 1),\n ('london, 1893', 1),\n ('boston: ticknor & co., 1886', 1),\n ('pp. xxvi, 375. london: jackson, walford & hodder; 1865', 1),\n ('pp. viii. 64. j. debrett: london, 1789', 1),\n ('g. eld: london, 1608', 1),\n ('j. y., for e. d. & n. e.: london, 1652', 1),\n ('for henry brome: london, 1661', 1),\n ('paris, amsterdam, 1768', 1),\n ('london, new york: george routledge & sons, [1882]', 1),\n ('london: printed by woodfall & kinder, 1860', 1),\n ('printed by h. e. carrington; london', 1),\n ('newcastle-upon-tyne, simpkin, marshall & co', 1),\n ('4 vol. parker & co.: oxford, 1891, 1892', 1)]"
     },
     "metadata": {},
     "execution_count": 198
    }
   ],
   "source": [
    "place_counter_no_name.most_common()[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publisher overview\n",
    "\n",
    "Here we are going to explore the `publisher` meta data in the same way as we did with authors and places. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Top 20 publishers\nPublisher: hurst & blackett\tCount: 418\nPublisher: macmillan & co.\tCount: 401\nPublisher: chatto & windus\tCount: 377\nPublisher: sampson low & co.\tCount: 374\nPublisher: chapman & hall\tCount: 315\nPublisher: longmans & co.\tCount: 296\nPublisher: london\tCount: 281\nPublisher: john murray\tCount: 274\nPublisher: f. v. white & co.\tCount: 259\nPublisher: privately printed\tCount: 252\nPublisher: r. bentley & son\tCount: 251\nPublisher: ward & downey\tCount: 247\nPublisher: cassell & co.\tCount: 246\nPublisher: smith, elder & co.\tCount: 216\nPublisher: hutchinson & co.\tCount: 216\nPublisher: printed for the author\tCount: 203\nPublisher: remington & co.\tCount: 183\nPublisher: w. blackwood & sons\tCount: 172\nPublisher: simpkin, marshall & co.\tCount: 171\nPublisher: g. routledge & sons\tCount: 167\n\nTotal number of publishers in the dataset: 7088\nNumber of publishers that only have one book in the dataset: 5177\n"
    }
   ],
   "source": [
    "publisher_counter = Counter()\n",
    "\n",
    "london_publishers = []\n",
    "for book in book_meta_data:\n",
    "    if 'publisher' in book:\n",
    "        publisher = book['publisher'].strip().lower()\n",
    "        if publisher:\n",
    "            publisher_counter.update([publisher])\n",
    "            if publisher == 'london':\n",
    "                london_publishers.append(book)\n",
    "\n",
    "print('Top 20 publishers')\n",
    "for publisher, count in publisher_counter.most_common(20):\n",
    "    print(f'Publisher: {publisher}\\tCount: {count}')\n",
    "\n",
    "print()\n",
    "print(f'Total number of publishers in the dataset: {len(publisher_counter)}')\n",
    "single_publishers = sum([count for count in publisher_counter.values() if count == 1])\n",
    "print(f'Number of publishers that only have one book in the dataset: {single_publishers}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is more similar to the `places` meta data, fewer single publishers (5177) and less publishers in total (7088). There are some publishers that are popular in the dataset, the most being `hurst & blackett`. However one publisher is interesting `london` which I thought would be a place name, thus an example of a book meta data is shown below where the publisher is `London`. We can see that the `publisher` meta data has been corrupted with the `place` meta data, in this example [A. Millar](https://en.wikipedia.org/wiki/Andrew_Millar) within the `place` meta data is probably referring to Andrew Millar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{\n    \"authors\": {\n        \"contributor\": [\n            \"HOME, John - Author of \\u201cDouglas.\\u201d\"\n        ]\n    },\n    \"corporate\": {},\n    \"date\": \"1758\",\n    \"datefield\": \"1758\",\n    \"edition\": \"\",\n    \"flickr_url_to_book_images\": \"http://www.flickr.com/photos/britishlibrary/tags/sysnum000029505\",\n    \"identifier\": \"000029505\",\n    \"imgs\": {\n        \"0\": {\n            \"000003\": [\n                \"10999869474\"\n            ],\n            \"000006\": [\n                \"10999792016\"\n            ],\n            \"000007\": [\n                \"10999931323\"\n            ],\n            \"000020\": [\n                \"10999934983\"\n            ],\n            \"000035\": [\n                \"10999795436\"\n            ],\n            \"000050\": [\n                \"10999869144\"\n            ],\n            \"000064\": [\n                \"10999871024\"\n            ]\n        }\n    },\n    \"issuance\": \"monographic\",\n    \"pdf\": {\n        \"0\": \"lsidyv33510698\"\n    },\n    \"place\": \"A. Millar\",\n    \"publisher\": \"London\",\n    \"shelfmarks\": [\n        \"British Library HMNTS 643.g.11.(7.)\",\n        \"British Library HMNTS 1607/5010.(2.)\"\n    ],\n    \"title\": [\n        \"Agis: a tragedy, etc. [In verse. By John Home.]\"\n    ]\n}\n"
    }
   ],
   "source": [
    "print(json.dumps(london_publishers[0], indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "London publishing problem starts at date 1667 and ends in 1898\n"
    }
   ],
   "source": [
    "date_range = sorted([int(book['date']) for book in london_publishers])\n",
    "print(f'London publishing problem starts at date {date_range[0]} and ends in {date_range[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the London `publisher` meta data problem is not within an old date range it covers almost the whole dataset data range from 1667 to 1898 and affects in total 281 books.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "To conclude we have covered:\n",
    "\n",
    "1. How to load the meta data.\n",
    "2. An examples of what each books meta data looks like.\n",
    "3. The number of books with meta data (49,509)\n",
    "4. Overview of the meta data that might be of interest.\n",
    "5. Explored some of the meta data fields.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-candidate"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36764bitbl19booksvirtualenv65f90d6035b0465eb1a2a7bf5950b08a",
   "display_name": "Python 3.6.7 64-bit ('bl-19-books': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}